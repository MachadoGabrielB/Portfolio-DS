{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle - Getting Started with SQL and BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "# dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "# dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# List all the tables in the \"hacker_news\" dataset\n",
    "# tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "# for table in tables:  \n",
    "#     print(table.table_id)\n",
    "\n",
    "# Construct a reference to the \"full\" table\n",
    "# table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "# table = client.get_table(table_ref)\n",
    "\n",
    "# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "# table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each SchemaField tells us about a specific column (which we also refer to as a field). In order, the information is:\n",
    "\n",
    "# The name of the column\n",
    "# The field type (or datatype) in the column\n",
    "# The mode of the column ('NULLABLE' means that a column allows NULL values, and is the default)\n",
    "# A description of the data in that column\n",
    "# The first field has the SchemaField:\n",
    "\n",
    "# SchemaField('by', 'string', 'NULLABLE', \"The username of the item's author.\",())\n",
    "\n",
    "# This tells us:\n",
    "\n",
    "# the field (or column) is called by,\n",
    "# the data in this field is strings,\n",
    "# NULL values are allowed, and\n",
    "# it contains the usernames corresponding to each item's author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first five lines of the \"full\" table\n",
    "# client.list_rows(table, max_results=5).to_dataframe()\n",
    "\n",
    "# Preview the first five entries in the \"by\" column of the \"full\" table\n",
    "# client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Client\" object\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# Set up the query\n",
    "# query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "# us_cities = query_job.to_dataframe()\n",
    "\n",
    "# What five cities have the most measurements?\n",
    "# us_cities.city.value_counts().head()\n",
    "\n",
    "# query = \"\"\"\n",
    "#         SELECT city, country\n",
    "#         FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "#         WHERE country = 'US'\n",
    "#         \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Query to get the score column from every row where the type column has value \"job\"\n",
    "# query = \"\"\"\n",
    "#         SELECT score, title\n",
    "#         FROM `bigquery-public-data.hacker_news.full`\n",
    "#         WHERE type = \"job\" \n",
    "#         \"\"\"\n",
    "\n",
    "# # Create a QueryJobConfig object to estimate size of query without running it\n",
    "# dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "\n",
    "# # API request - dry run query to estimate costs\n",
    "# dry_run_query_job = client.query(query, job_config=dry_run_config)\n",
    "\n",
    "# print(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only run the query if it's less than 1 MB\n",
    "# ONE_MB = 1000*1000\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n",
    "\n",
    "# # Set up the query (will only run if it's less than 1 MB)\n",
    "# safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# # API request - try to run the query, and return a pandas DataFrame\n",
    "# safe_query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code goes here\n",
    "# country_spend_pct_query = \"\"\"\n",
    "#                           SELECT country_name, AVG(value) AS avg_ed_spending_pct\n",
    "#                           FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "#                           WHERE (year BETWEEN 2010 AND 2017) AND (indicator_code = 'SE.XPD.TOTL.GD.ZS')\n",
    "#                           GROUP BY country_name\n",
    "#                           ORDER BY avg_ed_spending_pct DESC\n",
    "#                           \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code goes here\n",
    "# code_count_query = \"\"\"\n",
    "# SELECT indicator_code, indicator_name, COUNT(1) AS num_rows\n",
    "# FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "# WHERE year = 2016 \n",
    "# GROUP BY indicator_code, indicator_name\n",
    "# HAVING COUNT(1) >= 175\n",
    "# ORDER BY COUNT(1) DESC\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setp 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here to find the table name\n",
    "\n",
    "# tables = list(client.list_tables(dataset))\n",
    "\n",
    "# for table in tables:\n",
    "#     print(table.table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write the table name as a string below\n",
    "# table_name = 'taxi_trips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here\n",
    "\n",
    "# # Construct a reference to the \"taxi_trips\" table\n",
    "# table_ref = dataset_ref.table(\"taxi_trips\")\n",
    "\n",
    "# # API request - fetch the table\n",
    "# table = client.get_table(table_ref)\n",
    "\n",
    "# # Print information on all the columns in the \"taxi_trips\" table in the \"chicago_taxi_trips\" dataset\n",
    "# #table.schema\n",
    "\n",
    "# # Preview the first five lines of the \"full\" table\n",
    "\n",
    "# client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code goes here\n",
    "# rides_per_year_query = \"\"\"\n",
    "# SELECT EXTRACT(YEAR FROM trip_start_timestamp) AS year, COUNT(1) AS num_trips\n",
    "# FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "# GROUP BY year\n",
    "# ORDER BY num_trips DESC\n",
    "# \"\"\"\n",
    "\n",
    "# # Set up the query (cancel the query if it would use too much of \n",
    "# # your quota)\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "# rides_per_year_query_job = client.query(rides_per_year_query, job_config=safe_config) # Your code goes here\n",
    "\n",
    "# # API request - run the query, and return a pandas DataFrame\n",
    "# rides_per_year_result = rides_per_year_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# # View results\n",
    "# print(rides_per_year_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code goes here\n",
    "# rides_per_month_query = \"\"\"\n",
    "# SELECT EXTRACT(MONTH FROM trip_start_timestamp) AS month, COUNT(1) AS num_trips\n",
    "# FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "# WHERE EXTRACT(YEAR FROM trip_start_timestamp) = 2016\n",
    "# GROUP BY month\n",
    "# ORDER BY month DESC\n",
    "# \"\"\"\n",
    "# # Set up the query\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "# rides_per_month_query_job = client.query(rides_per_month_query, job_config=safe_config) # Your code goes here\n",
    "\n",
    "# # API request - run the query, and return a pandas DataFrame\n",
    "# rides_per_month_result = rides_per_month_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# # View results\n",
    "# print(rides_per_month_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Query to determine the number of files per license, sorted by number of files\n",
    "# query = \"\"\"\n",
    "#         SELECT L.license, COUNT(1) AS number_of_files\n",
    "#         FROM `bigquery-public-data.github_repos.sample_files` AS sf\n",
    "#         INNER JOIN `bigquery-public-data.github_repos.licenses` AS L \n",
    "#             ON sf.repo_name = L.repo_name\n",
    "#         GROUP BY L.license\n",
    "#         ORDER BY number_of_files DESC\n",
    "#         \"\"\"\n",
    "\n",
    "# # Set up the query (cancel the query if it would use too much of \n",
    "# # your quota, with the limit set to 10 GB)\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "# query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# # API request - run the query, and convert the results to a pandas DataFrame\n",
    "# file_count_by_license = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a list of available tables \n",
    "# tables = list(client.list_tables(dataset)) # Your code here\n",
    "\n",
    "# list_of_tables = [table.table_id for table in tables]\n",
    "\n",
    "# # # Print your answer\n",
    "# print(list_of_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here\n",
    "# questions_query = \"\"\"\n",
    "#                   SELECT id, title, owner_user_id\n",
    "#                   FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "#                   WHERE tags LIKE '%bigquery%'\n",
    "#                   \"\"\"\n",
    "\n",
    "# # Set up the query (cancel the query if it would use too much of \n",
    "# # your quota, with the limit set to 1 GB)\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "# questions_query_job = client.query(questions_query, job_config=safe_config) # Your code goes here\n",
    "\n",
    "# # API request - run the query, and return a pandas DataFrame\n",
    "# questions_results = questions_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# # Preview results\n",
    "# print(questions_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here\n",
    "# answers_query = \"\"\"\n",
    "# SELECT a.id AS id, a.body AS body, a.owner_user_id AS owner_user_id\n",
    "# FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "# INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "#     ON q.id = a.parent_id\n",
    "# WHERE q.tags LIKE '%bigquery%'\n",
    "# \"\"\"\n",
    "\n",
    "# # Set up the query\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=27*10**10)\n",
    "# answers_query_job = client.query(answers_query, job_config=safe_config) # Your code goes here\n",
    "\n",
    "# # API request - run the query, and return a pandas DataFrame\n",
    "# answers_results = answers_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# # Preview results\n",
    "# print(answers_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here\n",
    "# bigquery_experts_query = \"\"\"\n",
    "# SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "# FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "# INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "#     ON q.id = a.parent_id\n",
    "# WHERE q.tags LIKE '%bigquery%'\n",
    "# GROUP BY user_id\n",
    "# \"\"\"\n",
    "\n",
    "# # Set up the query\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "# bigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config) # Your code goes here\n",
    "\n",
    "# # API request - run the query, and return a pandas DataFrame\n",
    "# bigquery_experts_results = bigquery_experts_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# # Preview results\n",
    "# print(bigquery_experts_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expert_finder(topic, client):\n",
    "#     '''\n",
    "#     Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n",
    "\n",
    "#     Inputs:\n",
    "#         topic: A string with the topic of interest\n",
    "#         client: A Client object that specifies the connection to the Stack Overflow dataset\n",
    "\n",
    "#     Outputs:\n",
    "#         results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n",
    "#     '''\n",
    "#     my_query = \"\"\"\n",
    "#                SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "#                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "#                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "#                    ON q.id = a.parent_Id\n",
    "#                WHERE q.tags like '%{topic}%'\n",
    "#                GROUP BY a.owner_user_id\n",
    "#                \"\"\"\n",
    "\n",
    "#     # Set up the query (a real service would have good error handling for \n",
    "#     # queries that scan too much data)\n",
    "#     safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n",
    "#     my_query_job = client.query(my_query, job_config=safe_config)\n",
    "\n",
    "#     # API request - run the query, and return a pandas DataFrame\n",
    "#     results = my_query_job.to_dataframe()\n",
    "\n",
    "#     return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
